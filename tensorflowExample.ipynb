{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thianjin/SCB_ET_ML_Training/blob/main/tensorflowExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4n862jqRx8A",
        "outputId": "7b0f4aa9-e668-4a27-869e-eda7ff9e09d4"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(xtr,ytr),(xts,yts) = fashion_mnist.load_data()\n",
        "print(xtr.shape)\n",
        "print(xts.shape)\n",
        "print(ytr.shape)\n",
        "print(yts.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3y4m_t6R-04",
        "outputId": "a0e11297-e662-4ce5-ab32-acb829689aee"
      },
      "source": [
        "names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "len(names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro1i34R4SB1H"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(xtr,ytr),(xts,yts) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3cViFTTSFJ7",
        "outputId": "a3eab15d-9cf3-40ae-8664-4f903d09c1b5"
      },
      "source": [
        "names = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "len(names)\n",
        "print(xtr.shape)\n",
        "print(xts.shape)\n",
        "print(ytr.shape)\n",
        "print(yts.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WvKLR9ShSJH-",
        "outputId": "85cf183e-5e97-40a6-bcc1-de5ecef3b31c"
      },
      "source": [
        "plt.imshow(xtr[55180],cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw57aNzTSL0K",
        "outputId": "872f8ae7-ec9e-4194-f9c8-c7a76d21cabc"
      },
      "source": [
        "ytr[55180]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ybcyb65FSNzv",
        "outputId": "3b466874-0e60-49a9-ec27-cc06375d14e3"
      },
      "source": [
        "names[ytr[55180]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sneaker'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgyH0rlXHEX",
        "outputId": "63795781-11c2-49a4-dbb1-9578046dd50b"
      },
      "source": [
        "## Preprocessing of data\n",
        "\n",
        "ytr\n",
        "\n",
        "# for multiclass classification, we need to onehotencode the labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "ytr = to_categorical(ytr)\n",
        "print(ytr.shape)\n",
        "yts = to_categorical(yts)\n",
        "print(yts.shape)\n",
        "\n",
        "# converting images into channel format\n",
        "print(xtr.shape)\n",
        "print(xts.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViVFy9VgXurJ",
        "outputId": "bd8f17d4-bfc1-4ad3-8913-fbce1fa27ef4"
      },
      "source": [
        "## modelling of Neural Network\n",
        "\n",
        "from tensorflow.keras import models,layers\n",
        "\n",
        "# creating input layer\n",
        "input_layer = layers.Input(shape=(28,28))\n",
        "\n",
        "# add a fltten layer, flatten layer flattens the array, e.g. a 5x5 array will be converted to 1x25\n",
        "# here we are using flatten layer to convert image of shape 28x28 to 1x784 so that each pixel can be fed to next layer\n",
        "ft = layers.Flatten()(input_layer)\n",
        "\n",
        "# add the first hidden layer -> full connnected layer where each neuron does weighted sum and activation function. such layers in tensorflow are termed as dense layers\n",
        "h1 = layers.Dense(200,activation='relu')(ft)\n",
        "\n",
        "# add the second hidden layer\n",
        "h2 = layers.Dense(100,activation='relu')(h1)\n",
        "\n",
        "# add the final output layer\n",
        "output_layer = layers.Dense(10,activation='softmax')(h2)\n",
        "\n",
        "\n",
        "model = models.Model(inputs=input_layer,outputs=output_layer)\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 178,110\n",
            "Trainable params: 178,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StCNmMPabAvF",
        "outputId": "12120b69-5182-4b76-d92b-1d82ede293ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# metrics - to check performance of the model e.g. - accuracy, recall, r2 score\n",
        "# optmizier - the optmizier which will update the weights and bais to minimize the error function, e.g. adam, sgd, RMSProp => we prefer using adam as it tunes learning rate automaticalllu\n",
        "# loss = how the overall error to be calculated, for regression - mse , for two class classification - binary_crossentropy, for multiclass classification - categorical_crossentropy\n",
        "model.compile(metrics=['accuracy'],optimizer='adam',loss='categorical_crossentropy')\n",
        "model.fit(xtr,ytr,epochs=10,batch_size=1000,validation_data=(xts,yts))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 2s 25ms/step - loss: 10.5876 - accuracy: 0.6827 - val_loss: 3.2225 - val_accuracy: 0.7584\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 2.2557 - accuracy: 0.7765 - val_loss: 1.9780 - val_accuracy: 0.7672\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.4576 - accuracy: 0.7982 - val_loss: 1.4191 - val_accuracy: 0.7962\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 1.0721 - accuracy: 0.8149 - val_loss: 1.2743 - val_accuracy: 0.7989\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.8796 - accuracy: 0.8288 - val_loss: 1.0842 - val_accuracy: 0.8122\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7605 - accuracy: 0.8360 - val_loss: 0.9596 - val_accuracy: 0.8222\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 1s 24ms/step - loss: 0.6606 - accuracy: 0.8445 - val_loss: 0.9245 - val_accuracy: 0.8176\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.5807 - accuracy: 0.8525 - val_loss: 0.8430 - val_accuracy: 0.8241\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.5260 - accuracy: 0.8592 - val_loss: 0.7773 - val_accuracy: 0.8282\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.4731 - accuracy: 0.8660 - val_loss: 0.7358 - val_accuracy: 0.8279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2453501450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}